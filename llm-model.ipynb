{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-29T18:55:42.549923Z",
     "start_time": "2023-07-29T18:54:31.018178500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.0.247-py3-none-any.whl (1.4 MB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4\n",
      "  Using cached numexpr-2.8.4-cp310-cp310-win_amd64.whl (92 kB)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
      "  Using cached openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting pydantic<2,>=1\n",
      "  Using cached pydantic-1.10.12-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Using cached dataclasses_json-0.5.13-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Using cached aiohttp-3.8.5-cp310-cp310-win_amd64.whl (323 kB)\n",
      "Collecting numpy<2,>=1\n",
      "  Using cached numpy-1.25.1-cp310-cp310-win_amd64.whl (15.0 MB)\n",
      "Collecting langsmith<0.1.0,>=0.0.11\n",
      "  Using cached langsmith-0.0.15-py3-none-any.whl (30 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Using cached SQLAlchemy-2.0.19-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.0-cp310-cp310-win_amd64.whl (44 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-2.0.2-cp310-cp310-win_amd64.whl (192 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, pydantic, numpy, mypy-extensions, multidict, marshmallow, greenlet, frozenlist, async-timeout, yarl, typing-inspect, SQLAlchemy, openapi-schema-pydantic, numexpr, langsmith, aiosignal, dataclasses-json, aiohttp, langchain\n",
      "Successfully installed SQLAlchemy-2.0.19 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.13 frozenlist-1.4.0 greenlet-2.0.2 langchain-0.0.247 langsmith-0.0.15 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 numexpr-2.8.4 numpy-1.25.1 openapi-schema-pydantic-1.2.4 pydantic-1.10.12 tenacity-8.2.2 typing-inspect-0.9.0 yarl-1.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Requirement already satisfied: requests in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Collecting tqdm>=4.42.1\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from huggingface_hub) (4.7.1)\n",
      "Requirement already satisfied: colorama in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from requests->huggingface_hub) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from requests->huggingface_hub) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\git_clone\\langchain-playground\\venv\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Installing collected packages: tqdm, fsspec, filelock, huggingface_hub\n",
      "Successfully installed filelock-3.12.2 fsspec-2023.6.0 huggingface_hub-0.16.4 tqdm-4.65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T18:57:16.572206100Z",
     "start_time": "2023-07-29T18:57:13.989044600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "from secret_key import huggingfacehub_key\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = huggingfacehub_key"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T19:17:00.129281400Z",
     "start_time": "2023-07-29T19:17:00.109212Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T19:17:03.296926500Z",
     "start_time": "2023-07-29T19:17:01.661417300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'Wie lautet Ihr Name?'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://huggingface.co/google/flan-t5-xl\n",
    "llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\",\n",
    "                     model_kwargs={\"temperature\":0.8, \"max_length\":512})\n",
    "\n",
    "llm(\"Translate English to German: What is you name?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T20:11:14.757098100Z",
     "start_time": "2023-07-29T20:11:14.041733700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'yes'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Can Barack Obama have a conversation with George Washington?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T20:12:08.733708200Z",
     "start_time": "2023-07-29T20:12:08.493619900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'George Washington died in 1799. Barack Obama was born in 1961. The answer: no.'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prompt template\n",
    "prompt = \"\"\"Question: Can Barack Obama have a conversation with George Washington?\n",
    "\n",
    "Let's think step by step.\n",
    "\n",
    "Answer: \"\"\"\n",
    "llm(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T20:12:32.457768400Z",
     "start_time": "2023-07-29T20:12:32.326422Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "template = \"\"\"Question {question}\n",
    "\n",
    "Let's think step by step.\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T20:12:50.622262100Z",
     "start_time": "2023-07-29T20:12:50.612835800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Question Can Barack Obama have a conversation with George Washington?\\n\\nLet's think step by step.\\n\\nAnswer: \""
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(question=\"Can Barack Obama have a conversation with George Washington?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T20:12:53.964928900Z",
     "start_time": "2023-07-29T20:12:53.922437700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument `prompt` is expected to be a string. Instead found <class 'langchain.prompts.prompt.PromptTemplate'>. If you want to run the LLM on multiple prompts, use `generate` instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mllm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\git_clone\\langchain-playground\\venv\\lib\\site-packages\\langchain\\llms\\base.py:780\u001B[0m, in \u001B[0;36mBaseLLM.__call__\u001B[1;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001B[0m\n\u001B[0;32m    778\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Check Cache and run the LLM on the given prompt and input.\"\"\"\u001B[39;00m\n\u001B[0;32m    779\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(prompt, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m--> 780\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    781\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArgument `prompt` is expected to be a string. Instead found \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    782\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(prompt)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. If you want to run the LLM on multiple prompts, use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`generate` instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    784\u001B[0m     )\n\u001B[0;32m    785\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    786\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[0;32m    787\u001B[0m         [prompt],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    795\u001B[0m     \u001B[38;5;241m.\u001B[39mtext\n\u001B[0;32m    796\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: Argument `prompt` is expected to be a string. Instead found <class 'langchain.prompts.prompt.PromptTemplate'>. If you want to run the LLM on multiple prompts, use `generate` instead."
     ]
    }
   ],
   "source": [
    "#No we need to use chains: To combine LLMs and Prompts in multi-step workflows\n",
    "llm(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-29T20:13:00.590952500Z",
     "start_time": "2023-07-29T20:13:00.541364400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
